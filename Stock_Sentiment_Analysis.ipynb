{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stock Sentiment Analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FarhanSajid1/MachineLearning/blob/master/Stock_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "s8d5VWWZ9uwn",
        "colab_type": "code",
        "outputId": "ae3cefcf-3551-4f84-b8de-be604dab70ca",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import files\n",
        "import os\n",
        "uploaded = files.upload()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0ef86385-38d8-4fc2-bf0e-7400aeebb7cd\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-0ef86385-38d8-4fc2-bf0e-7400aeebb7cd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving twitter.csv to twitter.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Yt0MbhHr-BUT",
        "colab_type": "code",
        "outputId": "206e906f-faad-4c2e-d06c-14445e9abff3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('twitter.csv')\n",
        "print(len(df))\n",
        "print(df.head())\n",
        "print(df.info())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000\n",
            "            created_at                                               text  \\\n",
            "0  2013-01-01 20:10:04  Kickers on my watchlist $XIDE $TRIT $SOQ $PNK ...   \n",
            "1  2013-01-01 20:33:37  \"@user: $AAPL MOVIE. 55% return for the FEAR/G...   \n",
            "2  2013-01-01 21:43:41  @user I'd be afraid to short $AMZN - they are ...   \n",
            "3  2013-01-02 01:49:48                             $MNTA Over $12.00 URL    \n",
            "4  2013-01-02 01:51:33                              $OI  Over $21.37 URL    \n",
            "\n",
            "  sentiment  \n",
            "0  positive  \n",
            "1  positive  \n",
            "2  positive  \n",
            "3  positive  \n",
            "4  positive  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5000 entries, 0 to 4999\n",
            "Data columns (total 3 columns):\n",
            "created_at    5000 non-null object\n",
            "text          5000 non-null object\n",
            "sentiment     5000 non-null object\n",
            "dtypes: object(3)\n",
            "memory usage: 117.3+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lTLBlzoK-MyL",
        "colab_type": "code",
        "outputId": "8bda1de5-c523-4887-9ee8-78b309fbf30b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(df.loc[df['sentiment'] == 'positive'])) #this returns the amount of positive samples we have\n",
        "print(len(df.loc[df['sentiment'] == 'negative'])) #this returns the amount of negative samples that we havve\n",
        "print(3350 + 1650)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3350\n",
            "1650\n",
            "5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cs2dme_G_JoE",
        "colab_type": "code",
        "outputId": "23e97f2f-50d5-4273-be63-59e1a673acfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Create numpy arrays with the values that we need. \n",
        "text = df['text'].values\n",
        "labels = df['sentiment'].values\n",
        "print(text.dtype)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Pqo_Erpw_bWe",
        "colab_type": "code",
        "outputId": "46eb8c15-668d-4fd1-ca42-de60810851d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# preprocess the data so that we can read it in the RNN\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        " \n",
        "#figuring out how many words should be in each padding sequence\n",
        "len_tokens=[len(token) for token in text]\n",
        "mean_value = np.mean(len_tokens) # 76.40 is the mean\n",
        "print(np.max(len_tokens)) # 140\n",
        "print(mean_value) # 76.40\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "140\n",
            "76.4056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FrjV3OwZApM6",
        "colab_type": "code",
        "outputId": "10078393-0ad7-49e8-bba3-0d5808a26a75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# creating testing and validation sampling\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "max_len = int(mean_value + 1* np.std(len_tokens)) # 112 l\n",
        "training = int(len((text)) * .8) # 4000\n",
        "testing = int(len((text)) * .2) # 1000\n",
        "\n",
        "max_words = 10000 # maximum words in our universal vocabulary\n",
        "tokenizer = Tokenizer(num_words = max_words)\n",
        "#fit the tokenizer on the text\n",
        "tokenizer.fit_on_texts(text)\n",
        "sequences = tokenizer.texts_to_sequences(text)\n",
        "\n",
        "#padding the data\n",
        "data = pad_sequences(sequences, maxlen = max_len)\n",
        "\n",
        "labels = np.asarray(labels)\n",
        "\n",
        "\n",
        "#shuffling and splitting the data!\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "X_train = data[: training]\n",
        "X_test = data[training:]\n",
        "\n",
        "y_train = labels[:training]\n",
        "y_test = labels[training:]\n",
        "\n",
        "#we need to label binarize the data\n",
        "\n",
        "encoder = LabelBinarizer()\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "y_test = encoder.fit_transform(y_test)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape) #this is for the sigmoid output binary\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4000, 112)\n",
            "(1000, 112)\n",
            "(4000, 1)\n",
            "(1000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pZcX1-6xCrVQ",
        "colab_type": "code",
        "outputId": "6b88d8a1-f19e-4059-d0dc-12bd7f186acb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "print(data[0]) #training sequence after the padding"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0   12 1167  190   28 4327  108   81   32 1130\n",
            " 4328   79    4  589  409    2  144   10   43   46  547  167   51   38]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DCLITSN5Cu7w",
        "colab_type": "code",
        "outputId": "223f1c17-5558-4077-eab6-8833e69ab35c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(text[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Kickers on my watchlist $XIDE $TRIT $SOQ $PNK $CPWR $BPZ $ALJ  trade method 1 or method 2, see prev posts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iBzhjXs3DLod",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
        "reverse_word_map"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1XHgs5eYDYMo",
        "colab_type": "code",
        "outputId": "3fdba73f-dab8-40bd-ba77-f757fd8eb83b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras import regularizers\n",
        "from keras import layers\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import LSTM, GRU\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(max_words, 128))\n",
        "# model.add(layers.(256,return_sequences=True, recurrent_dropout = .1, kernel_regularizer = regularizers.l2(0.001)))\n",
        "# model.add(layers.Dropout(.1))\n",
        "# model.add(layers.GRU(128,return_sequences=True, recurrent_dropout = .2, kernel_regularizer = regularizers.l2(0.001)))\n",
        "# model.add(layers.Dropout(.2))\n",
        "# model.add(layers.GRU(64,return_sequences=True, recurrent_dropout = .1, kernel_regularizer = regularizers.l2(0.001)))\n",
        "# model.add(layers.Dropout(.2))\n",
        "# model.add(layers.GRU(32, kernel_regularizer = regularizers.l2(0.001)))\n",
        "# model.add(layers.Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.add(Bidirectional(GRU(128, return_sequences = True,  kernel_regularizer = regularizers.l2(0.001), recurrent_dropout = .2)))\n",
        "model.add(layers.Dropout(.2))\n",
        "model.add(Bidirectional(GRU(64, return_sequences = True,  kernel_regularizer = regularizers.l2(0.1))))\n",
        "model.add(Bidirectional(GRU(32,  kernel_regularizer = regularizers.l2(0.1))))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['acc'])\n",
        "history = model.fit(X_train, y_train, epochs = 8, batch_size = 128, validation_data = [X_test, y_test])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4000 samples, validate on 1000 samples\n",
            "Epoch 1/8\n",
            "4000/4000 [==============================] - 76s 19ms/step - loss: 40.3196 - acc: 0.6680 - val_loss: 23.9190 - val_acc: 0.7040\n",
            "Epoch 2/8\n",
            "4000/4000 [==============================] - 71s 18ms/step - loss: 15.6305 - acc: 0.7935 - val_loss: 8.6860 - val_acc: 0.7720\n",
            "Epoch 3/8\n",
            "4000/4000 [==============================] - 71s 18ms/step - loss: 5.0835 - acc: 0.8708 - val_loss: 2.5653 - val_acc: 0.7520\n",
            "Epoch 4/8\n",
            "4000/4000 [==============================] - 71s 18ms/step - loss: 1.3245 - acc: 0.9125 - val_loss: 1.0160 - val_acc: 0.7840\n",
            "Epoch 5/8\n",
            "4000/4000 [==============================] - 71s 18ms/step - loss: 0.3938 - acc: 0.9360 - val_loss: 1.0282 - val_acc: 0.7520\n",
            "Epoch 6/8\n",
            "4000/4000 [==============================] - 71s 18ms/step - loss: 0.2305 - acc: 0.9483 - val_loss: 0.6351 - val_acc: 0.7710\n",
            "Epoch 7/8\n",
            "4000/4000 [==============================] - 71s 18ms/step - loss: 0.1925 - acc: 0.9560 - val_loss: 0.5396 - val_acc: 0.7920\n",
            "Epoch 8/8\n",
            "4000/4000 [==============================] - 72s 18ms/step - loss: 0.3051 - acc: 0.9285 - val_loss: 0.8481 - val_acc: 0.7510\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ebHo85tdhA_O",
        "colab_type": "code",
        "outputId": "ab6f77a8-3765-4223-a12a-43c269648222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#evaluating the accuracy of the network\n",
        "\n",
        "result = model.evaluate(X_test, y_test)\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 6s 6ms/step\n",
            "[0.848092288017273, 0.751]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "109sGLOnhhGK",
        "colab_type": "code",
        "outputId": "7db8b6ea-f200-4c0c-9561-b12a6426de14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# analyzing the misclassified text\n",
        "\n",
        "y_predict = model.predict(x=X_test[0:100]) #testing on the first 100\n",
        "y_predict = y_predict\n",
        "y_predict.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "lNmxVQCyh0UU",
        "colab_type": "code",
        "outputId": "ea7660f8-6844-45c8-93fd-74e3d5851634",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clas_pred = np.array([1 if p >.5 else 0 for p in y_predict])\n",
        "# this is a one liner which will convert anything that is greater than .5 to a 1, making it fire a 1, and anything lower as a 0\n",
        "#this way it makes classification easier. As opposed to numbers between 0-1 we have values 0 or 1\n",
        "#finally the last reason why we do this is so that we can compare these values to the values that we expect to be in the classificaiton\n",
        "true_values = np.array(y_test[0:100]) #these are the true labels\n",
        "incorrect = np.where(clas_pred != true_values)\n",
        "true_values.shape\n",
        "incorrect\n",
        "# print(incorrect[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0,  0,  0, ..., 99, 99, 99]), array([ 3,  6,  7, ..., 93, 97, 98]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "unlMcG12ky-Q",
        "colab_type": "code",
        "outputId": "4b2d73a5-a69b-4e31-f25d-1fa531e709b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A3DLPxd2iiey",
        "colab_type": "code",
        "outputId": "0d96a5e6-7f08-43ee-d5d9-c27babf4de01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "idices = incorrect[0]\n",
        "idices"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  0,  0, ..., 99, 99, 99])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "4CQAQaMMkUgN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "idx = tokenizer.word_index\n",
        "inverse_map = dict(zip(idx.values(), idx.keys()))\n",
        "def tokens_to_string(tokens):\n",
        "    # Map from tokens back to words.\n",
        "    words = [inverse_map[token] for token in tokens if token != 0]\n",
        "    \n",
        "    # Concatenate all words.\n",
        "    text = \" \".join(words)\n",
        "\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NSeFw2hjkI3J",
        "colab_type": "code",
        "outputId": "b4adedfc-cd67-4143-c0d5-a79104909dbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "print(text[idices])\n",
        "print(labels[idices])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Kickers on my watchlist $XIDE $TRIT $SOQ $PNK $CPWR $BPZ $ALJ  trade method 1 or method 2, see prev posts'\n",
            " 'Kickers on my watchlist $XIDE $TRIT $SOQ $PNK $CPWR $BPZ $ALJ  trade method 1 or method 2, see prev posts'\n",
            " 'Kickers on my watchlist $XIDE $TRIT $SOQ $PNK $CPWR $BPZ $ALJ  trade method 1 or method 2, see prev posts'\n",
            " ... '$VRNG buys vs. Sells?' '$VRNG buys vs. Sells?'\n",
            " '$VRNG buys vs. Sells?']\n",
            "['negative' 'negative' 'negative' ... 'positive' 'positive' 'positive']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JsOSql3XmjN0",
        "colab_type": "code",
        "outputId": "82d426ad-e4d2-4321-f683-7d1197c84be7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# this is testing some random text to see if it is positve or negative. \n",
        "# text1 = '$APPL is definitely going to run. I expect it to gain .15c today!'\n",
        "text2 = 'Sell APPL stocks now!'\n",
        "textsl = [text2]\n",
        "tokens = tokenizer.texts_to_sequences(textsl)\n",
        "tokens_pad = pad_sequences(tokens, maxlen = max_len)\n",
        "prediction = model.predict_classes(tokens_pad)\n",
        "prediction"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "1v20-x66nxoF",
        "colab_type": "code",
        "outputId": "b529960a-fa76-4b40-8b46-fd8b39f05a08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17034
        }
      },
      "cell_type": "code",
      "source": [
        "#how to get the indexes of all the true negative values\n",
        "negatively = df.loc[df['sentiment'] == 'negative']\n",
        "values = negatively.index.tolist()\n",
        "values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6,\n",
              " 7,\n",
              " 21,\n",
              " 26,\n",
              " 31,\n",
              " 34,\n",
              
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "NgcQUckXojKB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#creating a new dataframe with just those negative values\n",
        "negative_df = df.iloc[values]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ghbrSsnXp0b0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "negative_text = negative_df['text'].values #this returns just the negative text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jQvlcPD7qHE5",
        "colab_type": "code",
        "outputId": "4865a298-c32d-4546-d822-81249f828d93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        }
      },
      "cell_type": "code",
      "source": [
        "# we will test on the first 100 negative values to see if they are classified correctly.\n",
        "# this is not a valid form of testing because most of the values have already been tested and trainied on..\n",
        "\n",
        "tokens = tokenizer.texts_to_sequences(negative_text[0:100])\n",
        "tokens_pad = pad_sequences(tokens, maxlen = max_len)\n",
        "prediction = model.predict_classes(tokens_pad)\n",
        "print(prediction)\n",
        "# false = np.where(prediction > .5)\n",
        "# false"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FOfUoDq5rGQ-",
        "colab_type": "code",
        "outputId": "6d2aa69b-13fa-4962-c3e4-9f6944bdd0af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "negative_text[12]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'$AIG American International Group Option Traders bet on 4% down move by next Friday URL '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "SdxFtMr_q1sW",
        "colab_type": "code",
        "outputId": "6f998988-1188-466b-8822-b7103c55b7b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "falsely_classified = negative_text[false[0]]\n",
        "print(falsely_classified[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "$LULU red, not ready for break out.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YYqvr7UOr25g",
        "colab_type": "code",
        "outputId": "96272dae-dbf7-49bb-c6a0-e4a60a7894c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1751
        }
      },
      "cell_type": "code",
      "source": [
        "#this is testing the sentiment analysis\n",
        "positive = df.loc[df['sentiment'] == 'positive']\n",
        "positive_text = positive['text'].values\n",
        "\n",
        "tokens = tokenizer.texts_to_sequences(positive_text[100:200])\n",
        "tokens_pad = pad_sequences(tokens, maxlen = max_len)\n",
        "pre = model.predict(tokens_pad)\n",
        "#predict_classes shows the output either a 0 or 1 making it much easier to intrepret\n",
        "pre = model.predict_classes(tokens_pad)\n",
        "print(pre)\n",
        "false = np.where(prediction > .5)\n",
        "false"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.9848696 ]\n",
            " [0.86262435]\n",
            " [0.98121625]\n",
            " [0.98884284]\n",
            " [0.07823612]\n",
            " [0.98560405]\n",
            " [0.9827214 ]\n",
            " [0.98902285]\n",
            " [0.97623116]\n",
            " [0.9893722 ]\n",
            " [0.98872584]\n",
            " [0.9781983 ]\n",
            " [0.9881813 ]\n",
            " [0.9683452 ]\n",
            " [0.99039453]\n",
            " [0.3597659 ]\n",
            " [0.9894567 ]\n",
            " [0.9867395 ]\n",
            " [0.9754174 ]\n",
            " [0.9892541 ]\n",
            " [0.983868  ]\n",
            " [0.9845463 ]\n",
            " [0.98686975]\n",
            " [0.9881045 ]\n",
            " [0.98976773]\n",
            " [0.08143286]\n",
            " [0.99023485]\n",
            " [0.98980707]\n",
            " [0.96539026]\n",
            " [0.95243573]\n",
            " [0.08189831]\n",
            " [0.98739296]\n",
            " [0.98809475]\n",
            " [0.983214  ]\n",
            " [0.9877029 ]\n",
            " [0.9847231 ]\n",
            " [0.9881516 ]\n",
            " [0.07540542]\n",
            " [0.93922687]\n",
            " [0.98620564]\n",
            " [0.9713596 ]\n",
            " [0.9841695 ]\n",
            " [0.98925215]\n",
            " [0.980911  ]\n",
            " [0.9877436 ]\n",
            " [0.9817535 ]\n",
            " [0.09801843]\n",
            " [0.9718165 ]\n",
            " [0.97959137]\n",
            " [0.97582936]\n",
            " [0.98114544]\n",
            " [0.9845255 ]\n",
            " [0.9856894 ]\n",
            " [0.9844387 ]\n",
            " [0.98794353]\n",
            " [0.97958714]\n",
            " [0.9862389 ]\n",
            " [0.06488881]\n",
            " [0.97880965]\n",
            " [0.8945298 ]\n",
            " [0.8124025 ]\n",
            " [0.98696274]\n",
            " [0.9868318 ]\n",
            " [0.9822174 ]\n",
            " [0.9867345 ]\n",
            " [0.9871897 ]\n",
            " [0.99065524]\n",
            " [0.98490477]\n",
            " [0.9758011 ]\n",
            " [0.98862517]\n",
            " [0.9609329 ]\n",
            " [0.9750183 ]\n",
            " [0.98200834]\n",
            " [0.98544955]\n",
            " [0.9841905 ]\n",
            " [0.9865769 ]\n",
            " [0.9397723 ]\n",
            " [0.9818286 ]\n",
            " [0.97873276]\n",
            " [0.98938555]\n",
            " [0.990157  ]\n",
            " [0.98378974]\n",
            " [0.98782736]\n",
            " [0.98806494]\n",
            " [0.98887897]\n",
            " [0.98909086]\n",
            " [0.99143714]\n",
            " [0.98642504]\n",
            " [0.97871727]\n",
            " [0.98615384]\n",
            " [0.98867536]\n",
            " [0.9538849 ]\n",
            " [0.8812759 ]\n",
            " [0.72176754]\n",
            " [0.9888016 ]\n",
            " [0.98162526]\n",
            " [0.98987514]\n",
            " [0.98308045]\n",
            " [0.98727417]\n",
            " [0.9888138 ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([18, 24, 28, 31, 34, 40, 45, 49, 52, 53, 56, 66, 67, 71, 80, 83, 97]),\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "PWJMtqzcs5qC",
        "colab_type": "code",
        "outputId": "297eaf4a-4426-44b6-c3be-9d4a98ec3392",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "cell_type": "code",
      "source": [
        "falsely_classified = positive_text[false[0]]\n",
        "print(len(falsely_classified)) # only 6 misclassifications in the positive test\n",
        "print(falsely_classified[:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17\n",
            "['Over extended stock market + unexpected news from the FED minutes = Down $EURUSD & a panicky $ES_F $NQ_F.'\n",
            " '$BAC what happens next? URL '\n",
            " '$AAPL moving down with volume. Couldnt cope with the descending trend line. Trend is still down. Perhaps 460 is not impossible after all.'\n",
            " '$AAPL people be realistic. Market undecided what to do with apple. Earnings will lift that cloud. If GOOD we might REALLY see a reversal.'\n",
            " \"$AMZN alert update: a last minute push tried to shake out puts. we're hanging on for now. URL \"\n",
            " '$HMA unusual option activity. Trader buys 11k of the Jan 9 Put. Short term bear play'\n",
            " '$ZNGA Still shows red and dead on a Renko view, PF Box size 0.25 URL '\n",
            " '@user $BAC Yeah ... they made the easy profits by slashing jobs, now they have to close win-win sales.'\n",
            " '$ko has trouble staying above 200 day sma past few weeks. could short here or higher stops above 38 URL '\n",
            " '$mako a red day monday breaks support and could test old lows of 9-9.25 URL '\n",
            " 'I think $AAPL is heading back down to check in on 506 support again'\n",
            " '$AA option traders bet on bad earnings selling 6,200 Jan 9C and buying 3,200 Jan 9P. Could be hedge on stock. Both trades against low OI'\n",
            " '$SKX Q3 operational cash flow negative $60million. $80million decline vs.Q3 2011'\n",
            " '3 horsemen of high beta momo chase $FSLR $GMCR $NFLX being slammed a bit here : advanced tell that the new year party is over for the mrkt ?'\n",
            " '$yum down premarket through the cloud but has support at about 62.75  URL '\n",
            " '$AYI Q1 Operational Cash Flow turns Negative'\n",
            " 'Let the angry, anecdotal comments begin: \"Why I still think BlackBerry & RIM are doomed.\" URL $RIMM $AAPL $GOOG $NOK $T $VZ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "99xkX93gtk8M",
        "colab_type": "code",
        "outputId": "6c7036c3-70f8-45b2-f05a-93371a7d0675",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "cell_type": "code",
      "source": [
        "print(positive_text[:20])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['$AAPL - @user if so then the current downtrend will break. Otherwise just a short-term correction in med-term downtrend.'\n",
            " \"Monday's relative weakness. $NYX $WIN $TIE $TAP $ICE $INTU $BMC $AON $CL $CHK $BIIB URL \"\n",
            " \"Won't believe $AAPL uptrend is back until it crosses above MA(50)\"\n",
            " '$LULU red, not ready for break out.'\n",
            " '\"@user: been adding $UVXY long off the bottom today for trade, also got $WPI near low\"'\n",
            " '$LNKD looking like a good short. Failed to break price level resistance at 116 today.'\n",
            " 'Too early to short into this move. Stock Market needs a few days to settle down. #Patience URL $COH $BWLD $DLTR $AAPL $PAY'\n",
            " '$PHM PulteGroup Option Bear bets $1.5 Million on 11% down move by April URL '\n",
            " 'Short Setups displaying relative weakness: $ARO $COH $PAY $BWLD $DLTR $SHLD $WTW $UPL Prepare to short the stall. $ES_F URL '\n",
            " '$SKUL to the GRAVE!'\n",
            " '$ovti ttm ending Oct 2012 Negative $151 million operational cash flow.. 273% decline vs yoy ttm ending oct 2011'\n",
            " '$GPS wow that wa s a fast fast fade...'\n",
            " '$AIG American International Group Option Traders bet on 4% down move by next Friday URL '\n",
            " 'New Sony pre-owned block tech patent unearthed $SNE ... 50% of $GME profits from \"pre owned\" ..last one out turn off the lights'\n",
            " '\"@user: $SPX 1464.90 Wave iv would be 20 points lower [1467.00 KEY] $ES_F HOD 1460.00 (under neckline 1458.50 very bearish) \"'\n",
            " 'Wow, not good for $BKS RT @user ... sales for the Nook were down 13% over the holidays URL '\n",
            " 'The new wightwatchers ads are more fun and light and with regular people more interesting, but I still dont trust them $WTW (no position)'\n",
            " '$AAPL $SPY no more QE for 2013. Now bring the Geithner.'\n",
            " 'Over extended stock market + unexpected news from the FED minutes = Down $EURUSD & a panicky $ES_F $NQ_F.'\n",
            " '$SPY Uncle Ben needed to spice up things a little. $AAPL people were bored, wake up now.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ACpoei5AsYRq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('stock_sentiment.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_PHjY4vqsoTU",
        "colab_type": "code",
        "outputId": "11321592-5c60-4a4e-b226-3aeaa312c14f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once in a notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Create & upload a file.\n",
        "uploaded = drive.CreateFile({'title': 'Stock_sentiment.h5'})\n",
        "uploaded.SetContentFile('stock_sentiment.h5')\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file with ID 1kNbLFXYLrbnA0dBNftXz5cSmSAk7oRMo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "grEQihM6vIUG",
        "colab_type": "code",
        "outputId": "b956f618-13d5-4db4-e83b-5cb56385f878",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "cell_type": "code",
      "source": [
        "predictions = model.predict_classes(x= X_test[:]) \n",
        "#this prints out the predictions in a more readible manner\n",
        "predictions = predictions.T[0]\n",
        "predictions"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
              "       1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
              "       1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
              "       0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0,\n",
              "       1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
              "       1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
              "       0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "       1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
              "       1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
              "       0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
              "       0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
              "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
              "       1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
              "       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
              "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
              "       0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "       1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "       0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
              "       0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
              "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
              "       1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "       1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
              "       0, 0, 0, 1, 1, 1, 1, 1, 1, 1], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "metadata": {
        "id": "VZt4OLGfw_Dy",
        "colab_type": "code",
        "outputId": "aa0d7e47-e1a2-4c0b-f358-391447f54057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "cell_type": "code",
      "source": [
        "print(y_test[:].T)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 0 0 1 1 0 0 1 0 1 1\n",
            "  1 1 0 0 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 1\n",
            "  1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 0 1 1\n",
            "  1 1 0 0 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1\n",
            "  1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0\n",
            "  1 0 1 0 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1\n",
            "  0 0 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 0 0 1 0 1 1\n",
            "  1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 0 1 0 1 0 1 1\n",
            "  1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1\n",
            "  1 1 0 0 1 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 1 0 1 1 0 0 0 0\n",
            "  1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 1 0 1 1 1 1\n",
            "  1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1\n",
            "  0 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1\n",
            "  0 1 0 0 0 1 0 1 0 0 0 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1\n",
            "  1 1 0 1 1 1 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 1 0\n",
            "  0 1 1 1 1 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0\n",
            "  1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1\n",
            "  1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 0 1 0 1\n",
            "  1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 1 1 0 1 0 0 1 1 1 0 1 1 1 0 0 1 1 1 0 1 0\n",
            "  1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1\n",
            "  0 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 0 0 1 1 1 1 1 0 1 1 1 1 1 1\n",
            "  0 0 1 1 0 0 0 1 1 0 1 0 0 0 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 1\n",
            "  1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 0 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 1\n",
            "  1 1 1 0 1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1\n",
            "  0 1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1\n",
            "  1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 0 0 1 1 1 0 0 1 1 1 0\n",
            "  1 1 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0 1 1 0 1 0 0 1 1 0 0 1 1 1 1 0 1 0 1 0\n",
            "  1 1 0 1 1 1 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 1 1 1 1 0 1 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ohlfMO9mwVeD",
        "colab_type": "code",
        "outputId": "ab9359c6-86e7-4266-b2ab-bf4005ad7646",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "correct = np.array(y_test[:].T) #these are the labels associated with those test variables that we gather\n",
        "incorrect= np.where(predictions != correct)\n",
        "incorrect = incorrect[0]\n",
        "print(len(incorrect))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "249\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uhB8HI_KzIdA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''From these tests we learned a couple things\n",
        "predict_classes predicts the output without any probabilities involved\n",
        "We can check which are incorrect by comparing the predicted probabilities with the actual \n",
        "labels.\n",
        "The reason why the np.where clause was not executing the first time was because of the .T we transposed\n",
        "the results in order to make the legible, but disregarded the fact that we would be comparing them to \n",
        "another array which would have differing dimensions.'''"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
