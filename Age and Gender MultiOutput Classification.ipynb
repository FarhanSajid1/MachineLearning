{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Age and Gender.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FarhanSajid1/MachineLearning/blob/master/Age%20and%20Gender%20MultiOutput%20Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "UtiYHFbZmQ6L",
        "colab_type": "code",
        "outputId": "c11a346d-5659-4f58-fa2b-6faae8610cbc",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "uploaded = files.upload()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b64aa8e3-fb41-4a44-8ab5-e85ab106c056\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-b64aa8e3-fb41-4a44-8ab5-e85ab106c056\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving genderage.zip to genderage (4).zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NmGi67vvn6H9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import io\n",
        "data = zipfile.ZipFile(io.BytesIO(uploaded['genderage.zip']), 'r')\n",
        "data.extractall()\n",
        "\n",
        "data.printdir()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YP1F_aT-qQR-",
        "colab_type": "code",
        "outputId": "06422a09-cdf3-48cc-a311-10722bc614ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install imutils"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting imutils\n",
            "  Downloading https://files.pythonhosted.org/packages/ee/29/6b20a2f2444be479cbd74b8fb0dd2ee92671e1c52360f1cb022c6c00e052/imutils-0.5.1.tar.gz\n",
            "Building wheels for collected packages: imutils\n",
            "  Running setup.py bdist_wheel for imutils ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/4c/ff/aa/824fb9efc5b8c740d54cd8bc19c7e85fbb8d115c77e56812c7\n",
            "Successfully built imutils\n",
            "Installing collected packages: imutils\n",
            "Successfully installed imutils-0.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QpPkQ9OboSyo",
        "colab_type": "code",
        "outputId": "dafeccbf-5642-407f-8728-2496763332f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import random\n",
        "import pickle\n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "0jXsSNvUpRTI",
        "colab_type": "code",
        "outputId": "ca18270c-4be6-46be-d9a0-6ff8b4cf157b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"[INFO] loading images...\")\n",
        "imagePaths = sorted(list(paths.list_images(\"genderage\")))\n",
        "random.seed(42)\n",
        "random.shuffle(imagePaths)\n",
        " \n",
        "# initialize the data, gender labels, along with the age labels\n",
        "data = []\n",
        "genderlabels = []\n",
        "agelabels = []"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading images...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ixjAWstXq1QK",
        "colab_type": "code",
        "outputId": "d938e2b9-120f-41c5-fe86-46b2dec99b97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(imagePaths))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9642\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AvQDRayCrBKS",
        "colab_type": "code",
        "outputId": "67d37ea2-9899-42bb-ecc0-6aef7e216093",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "IMAGE_DIMS = (150, 150, 3)\n",
        "\n",
        "for imagePath in imagePaths:\n",
        "\t# load the image, pre-process it, and store it in the data list\n",
        "\timage = cv2.imread(imagePath)\n",
        "\timage = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
        "\timage = img_to_array(image)\n",
        "\tdata.append(image)\n",
        "  \n",
        " \n",
        "\t# extract the gender and age labels\n",
        "\t# update the respective lists\n",
        "\t(gender, age) = imagePath.split(os.path.sep)[-2].split(\"_\")\n",
        "\tgenderlabels.append(gender)\n",
        "\tagelabels.append(age)\n",
        "  \n",
        "  \n",
        "  \n",
        "print('done')\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g83uCk4h2SqP",
        "colab_type": "code",
        "outputId": "b0d26f02-a828-4169-b680-63270d67b270",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "print(genderlabels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ['female', 'female', 'female', 'female', 'male', 'male', 'female', 'male', 'male', 'male', 'female', 'male', 'female'],  
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iKC15SP-sF9k",
        "colab_type": "code",
        "outputId": "afdcf2a0-b479-4e91-d273-f3210e20b871",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "'''convert the data and labels into arrays and binize the etc..'''\n",
        "\n",
        "\n",
        "data = np.array(data, dtype ='float')/255 # 255 pixels..\n",
        "\n",
        "#converting the labels into arrays as well\n",
        "genderlabels = np.array(genderlabels)\n",
        "print(genderlabels)\n",
        "agelabels = np.array(agelabels)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['female' 'female' 'female' ... 'female' 'female' 'female']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ddU6Z2F3fbZq",
        "colab_type": "code",
        "outputId": "ad3639ec-1600-48ab-c21a-574afe5c186e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "print(genderlabels[:20])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['female' 'female' 'female' 'female' 'male' 'male' 'female' 'male' 'male'\n",
            " 'male' 'female' 'male' 'female' 'female' 'male' 'male' 'male' 'male'\n",
            " 'female' 'male']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NcAr6oPE75YM",
        "colab_type": "code",
        "outputId": "d0cf4104-50ea-4564-f458-5c53ce3a09d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "#binarize the labels to make it easier for the neural network\n",
        "from keras.utils import to_categorical\n",
        "genderbinizer = LabelBinarizer()\n",
        "agebinizer = LabelBinarizer()\n",
        "\n",
        "genderlabels = genderbinizer.fit_transform(genderlabels)\n",
        "print(genderlabels)\n",
        "# genderlabels = to_categorical(genderlabels, num_classes = 2)\n",
        "print(genderlabels)\n",
        "agelabels = agebinizer.fit_transform(agelabels)\n",
        "\n",
        "print('converting to array is complete')\n",
        "\n",
        "#now we split the data.\n",
        "\n",
        "\n",
        "(trainX, testX, traingendery, testgendery, trainagey, testagey) = train_test_split(data, genderlabels, agelabels, test_size = .2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " ...\n",
            " [0]\n",
            " [0]\n",
            " [0]]\n",
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " ...\n",
            " [0]\n",
            " [0]\n",
            " [0]]\n",
            "converting to array is complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aPLX3GgsflhW",
        "colab_type": "code",
        "outputId": "aeca1e55-7501-432b-c454-1a2fe291dd13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "cell_type": "code",
      "source": [
        "print(genderlabels[:20])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0]\n",
            " [0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XvLbU9-KcsRs",
        "colab_type": "code",
        "outputId": "90513c4a-5974-4060-86ed-dd3f7876f8ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(genderlabels[0].argmax())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yOA7SG4zo1St",
        "colab_type": "code",
        "outputId": "4af99414-91be-4e91-c8c7-6674186a06b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "cell_type": "code",
      "source": [
        "#creating the model and testing it\n",
        "\n",
        "from keras.applications import VGG16\n",
        "from keras import Model\n",
        "from keras import Input\n",
        "from keras.layers import Flatten\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "\n",
        "conv_base = VGG16(weights = 'imagenet',\n",
        "                 include_top = False,\n",
        "                 input_shape = (150,150,3))\n",
        "\n",
        "inputs = Input(shape = (150, 150, 3))\n",
        "x = conv_base(inputs)\n",
        "x = Flatten()(x)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "x = layers.Dropout(.5)(x)\n",
        "x = layers.Dense(156, activation='relu')(x)\n",
        "gender_prediction = layers.Dense(1, activation = 'sigmoid', name='gender')(x)\n",
        "\n",
        "\n",
        "x = conv_base(inputs)\n",
        "x = Flatten()(x)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "age_prediction = layers.Dense(4, activation = 'softmax', name='age')(x)\n",
        "\n",
        "model = Model(inputs, [gender_prediction, age_prediction])\n",
        "\n",
        "model.compile(optimizer= optimizers.RMSprop(lr=2e-5),\n",
        "             loss = {'gender': 'binary_crossentropy', 'age': 'categorical_crossentropy'},\n",
        "             metrics = ['accuracy'],\n",
        "             loss_weights = {'gender': 10, 'age': 1})\n",
        "\n",
        "model.fit(trainX,\n",
        "         {'gender': traingendery, 'age': trainagey},\n",
        "         validation_data = (testX, {'gender': testgendery, 'age': testagey}), epochs= 15, batch_size = 256)\n",
        "\n",
        "model.save('age_and_gender2.h5')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7713 samples, validate on 1929 samples\n",
            "Epoch 1/15\n",
            "7713/7713 [==============================] - 130s 17ms/step - loss: 6.8309 - gender_loss: 0.6044 - age_loss: 0.7865 - gender_acc: 0.6541 - age_acc: 0.7211 - val_loss: 5.4581 - val_gender_loss: 0.4833 - val_age_loss: 0.6247 - val_gender_acc: 0.7564 - val_age_acc: 0.7932\n",
            "Epoch 2/15\n",
            "7713/7713 [==============================] - 122s 16ms/step - loss: 5.0674 - gender_loss: 0.4458 - age_loss: 0.6098 - gender_acc: 0.7824 - age_acc: 0.7809 - val_loss: 4.5631 - val_gender_loss: 0.3936 - val_age_loss: 0.6267 - val_gender_acc: 0.7999 - val_age_acc: 0.7615\n",
            "Epoch 3/15\n",
            "7713/7713 [==============================] - 122s 16ms/step - loss: 4.4806 - gender_loss: 0.3916 - age_loss: 0.5648 - gender_acc: 0.8169 - age_acc: 0.7923 - val_loss: 4.0223 - val_gender_loss: 0.3468 - val_age_loss: 0.5544 - val_gender_acc: 0.8237 - val_age_acc: 0.7895\n",
            "Epoch 4/15\n",
            "7713/7713 [==============================] - 122s 16ms/step - loss: 4.0023 - gender_loss: 0.3474 - age_loss: 0.5283 - gender_acc: 0.8382 - age_acc: 0.8031 - val_loss: 3.8466 - val_gender_loss: 0.3212 - val_age_loss: 0.6343 - val_gender_acc: 0.8450 - val_age_acc: 0.7657\n",
            "Epoch 5/15\n",
            "7713/7713 [==============================] - 122s 16ms/step - loss: 3.6639 - gender_loss: 0.3158 - age_loss: 0.5059 - gender_acc: 0.8576 - age_acc: 0.8106 - val_loss: 4.6363 - val_gender_loss: 0.4125 - val_age_loss: 0.5113 - val_gender_acc: 0.7890 - val_age_acc: 0.8170\n",
            "Epoch 6/15\n",
            "7713/7713 [==============================] - 122s 16ms/step - loss: 3.4805 - gender_loss: 0.3006 - age_loss: 0.4745 - gender_acc: 0.8596 - age_acc: 0.8190 - val_loss: 3.7205 - val_gender_loss: 0.3205 - val_age_loss: 0.5160 - val_gender_acc: 0.8523 - val_age_acc: 0.8108\n",
            "Epoch 7/15\n",
            "7713/7713 [==============================] - 122s 16ms/step - loss: 3.1158 - gender_loss: 0.2662 - age_loss: 0.4534 - gender_acc: 0.8825 - age_acc: 0.8256 - val_loss: 4.7062 - val_gender_loss: 0.4141 - val_age_loss: 0.5650 - val_gender_acc: 0.8258 - val_age_acc: 0.7900\n",
            "Epoch 8/15\n",
            "7713/7713 [==============================] - 122s 16ms/step - loss: 2.8415 - gender_loss: 0.2408 - age_loss: 0.4333 - gender_acc: 0.8955 - age_acc: 0.8318 - val_loss: 4.8578 - val_gender_loss: 0.4263 - val_age_loss: 0.5947 - val_gender_acc: 0.8212 - val_age_acc: 0.7703\n",
            "Epoch 9/15\n",
            "7713/7713 [==============================] - 122s 16ms/step - loss: 2.6924 - gender_loss: 0.2296 - age_loss: 0.3964 - gender_acc: 0.9029 - age_acc: 0.8496 - val_loss: 3.4423 - val_gender_loss: 0.2944 - val_age_loss: 0.4987 - val_gender_acc: 0.8600 - val_age_acc: 0.8077\n",
            "Epoch 10/15\n",
            "7713/7713 [==============================] - 122s 16ms/step - loss: 2.4562 - gender_loss: 0.2049 - age_loss: 0.4071 - gender_acc: 0.9146 - age_acc: 0.8436 - val_loss: 3.3036 - val_gender_loss: 0.2812 - val_age_loss: 0.4913 - val_gender_acc: 0.8709 - val_age_acc: 0.8144\n",
            "Epoch 11/15\n",
            "7713/7713 [==============================] - 122s 16ms/step - loss: 2.2727 - gender_loss: 0.1912 - age_loss: 0.3611 - gender_acc: 0.9192 - age_acc: 0.8608 - val_loss: 3.6708 - val_gender_loss: 0.3118 - val_age_loss: 0.5529 - val_gender_acc: 0.8637 - val_age_acc: 0.7843\n",
            "Epoch 12/15\n",
            "7713/7713 [==============================] - 122s 16ms/step - loss: 2.0650 - gender_loss: 0.1705 - age_loss: 0.3599 - gender_acc: 0.9296 - age_acc: 0.8643 - val_loss: 4.5908 - val_gender_loss: 0.3614 - val_age_loss: 0.9769 - val_gender_acc: 0.8564 - val_age_acc: 0.6698\n",
            "Epoch 13/15\n",
            "7713/7713 [==============================] - 122s 16ms/step - loss: 1.9710 - gender_loss: 0.1613 - age_loss: 0.3583 - gender_acc: 0.9356 - age_acc: 0.8670 - val_loss: 4.6336 - val_gender_loss: 0.4086 - val_age_loss: 0.5473 - val_gender_acc: 0.8419 - val_age_acc: 0.8072\n",
            "Epoch 14/15\n",
            "7713/7713 [==============================] - 122s 16ms/step - loss: 1.8124 - gender_loss: 0.1498 - age_loss: 0.3144 - gender_acc: 0.9426 - age_acc: 0.8832 - val_loss: 3.8092 - val_gender_loss: 0.3274 - val_age_loss: 0.5352 - val_gender_acc: 0.8590 - val_age_acc: 0.7999\n",
            "Epoch 15/15\n",
            "7713/7713 [==============================] - 122s 16ms/step - loss: 1.8151 - gender_loss: 0.1494 - age_loss: 0.3211 - gender_acc: 0.9414 - age_acc: 0.8802 - val_loss: 3.3581 - val_gender_loss: 0.2881 - val_age_loss: 0.4771 - val_gender_acc: 0.8642 - val_age_acc: 0.8160\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jSDcCTUatwDM",
        "colab_type": "code",
        "outputId": "d86cce7b-d998-4da1-fb67-65fbb9aa5f52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "cell_type": "code",
      "source": [
        "#creating the model and testing it\n",
        "\n",
        "from keras.applications import VGG16\n",
        "from keras import Model\n",
        "from keras import Input\n",
        "from keras.layers import Flatten\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "\n",
        "conv_base = VGG16(weights = 'imagenet',\n",
        "                 include_top = False,\n",
        "                 input_shape = (150,150,3))\n",
        "\n",
        "inputs = Input(shape = (150, 150, 3))\n",
        "x = conv_base(inputs)\n",
        "x = Flatten()(x)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "x = layers.Dropout(.5)(x)\n",
        "x = layers.Dense(156, activation='relu')(x)\n",
        "gender_prediction = layers.Dense(1, activation = 'sigmoid', name='gender')(x)\n",
        "\n",
        "\n",
        "x = conv_base(inputs)\n",
        "x = Flatten()(x)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "x = layers.Dropout(.5)(x)\n",
        "age_prediction = layers.Dense(4, activation = 'softmax', name='age')(x)\n",
        "\n",
        "model = Model(inputs, [gender_prediction, age_prediction])\n",
        "\n",
        "model.compile(optimizer= optimizers.RMSprop(lr=2e-5),\n",
        "             loss = {'gender': 'binary_crossentropy', 'age': 'categorical_crossentropy'},\n",
        "             metrics = ['accuracy'])\n",
        "\n",
        "model.fit(trainX,\n",
        "         {'gender': traingendery, 'age': trainagey},\n",
        "         validation_data = (testX, {'gender': testgendery, 'age': testagey}), epochs= 20, batch_size = 128)\n",
        "\n",
        "model.save('age_and_gender1.h5')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7713 samples, validate on 1929 samples\n",
            "Epoch 1/20\n",
            "7713/7713 [==============================] - 130s 17ms/step - loss: 1.3986 - gender_loss: 0.5939 - age_loss: 0.8046 - gender_acc: 0.6687 - age_acc: 0.7135 - val_loss: 1.2078 - val_gender_loss: 0.4849 - val_age_loss: 0.7230 - val_gender_acc: 0.7506 - val_age_acc: 0.7258\n",
            "Epoch 2/20\n",
            "7713/7713 [==============================] - 109s 14ms/step - loss: 1.0377 - gender_loss: 0.4517 - age_loss: 0.5860 - gender_acc: 0.7867 - age_acc: 0.7786 - val_loss: 0.9244 - val_gender_loss: 0.3861 - val_age_loss: 0.5383 - val_gender_acc: 0.8300 - val_age_acc: 0.7994\n",
            "Epoch 3/20\n",
            "7713/7713 [==============================] - 109s 14ms/step - loss: 0.8889 - gender_loss: 0.3914 - age_loss: 0.4974 - gender_acc: 0.8154 - age_acc: 0.8123 - val_loss: 0.8199 - val_gender_loss: 0.3697 - val_age_loss: 0.4502 - val_gender_acc: 0.8263 - val_age_acc: 0.8227\n",
            "Epoch 4/20\n",
            "7713/7713 [==============================] - 109s 14ms/step - loss: 0.8118 - gender_loss: 0.3518 - age_loss: 0.4600 - gender_acc: 0.8392 - age_acc: 0.8246 - val_loss: 0.8279 - val_gender_loss: 0.3592 - val_age_loss: 0.4687 - val_gender_acc: 0.8253 - val_age_acc: 0.8113\n",
            "Epoch 5/20\n",
            "7713/7713 [==============================] - 109s 14ms/step - loss: 0.7297 - gender_loss: 0.3119 - age_loss: 0.4178 - gender_acc: 0.8622 - age_acc: 0.8365 - val_loss: 0.9191 - val_gender_loss: 0.4027 - val_age_loss: 0.5164 - val_gender_acc: 0.8139 - val_age_acc: 0.7786\n",
            "Epoch 6/20\n",
            "7713/7713 [==============================] - 109s 14ms/step - loss: 0.6569 - gender_loss: 0.2833 - age_loss: 0.3736 - gender_acc: 0.8775 - age_acc: 0.8512 - val_loss: 0.8454 - val_gender_loss: 0.3332 - val_age_loss: 0.5123 - val_gender_acc: 0.8409 - val_age_acc: 0.7869\n",
            "Epoch 7/20\n",
            "7713/7713 [==============================] - 109s 14ms/step - loss: 0.6072 - gender_loss: 0.2508 - age_loss: 0.3564 - gender_acc: 0.8943 - age_acc: 0.8649 - val_loss: 0.7236 - val_gender_loss: 0.2903 - val_age_loss: 0.4332 - val_gender_acc: 0.8709 - val_age_acc: 0.8232\n",
            "Epoch 8/20\n",
            "7713/7713 [==============================] - 109s 14ms/step - loss: 0.5524 - gender_loss: 0.2377 - age_loss: 0.3147 - gender_acc: 0.8990 - age_acc: 0.8803 - val_loss: 0.7500 - val_gender_loss: 0.2988 - val_age_loss: 0.4511 - val_gender_acc: 0.8580 - val_age_acc: 0.8196\n",
            "Epoch 9/20\n",
            "7713/7713 [==============================] - 109s 14ms/step - loss: 0.5013 - gender_loss: 0.2096 - age_loss: 0.2916 - gender_acc: 0.9161 - age_acc: 0.8846 - val_loss: 0.8068 - val_gender_loss: 0.3050 - val_age_loss: 0.5017 - val_gender_acc: 0.8673 - val_age_acc: 0.8258\n",
            "Epoch 10/20\n",
            "7713/7713 [==============================] - 109s 14ms/step - loss: 0.4550 - gender_loss: 0.1887 - age_loss: 0.2663 - gender_acc: 0.9210 - age_acc: 0.8968 - val_loss: 0.8121 - val_gender_loss: 0.2991 - val_age_loss: 0.5131 - val_gender_acc: 0.8730 - val_age_acc: 0.8046\n",
            "Epoch 11/20\n",
            "7713/7713 [==============================] - 109s 14ms/step - loss: 0.4216 - gender_loss: 0.1713 - age_loss: 0.2503 - gender_acc: 0.9314 - age_acc: 0.9047 - val_loss: 0.7167 - val_gender_loss: 0.2971 - val_age_loss: 0.4197 - val_gender_acc: 0.8782 - val_age_acc: 0.8274\n",
            "Epoch 12/20\n",
            "7713/7713 [==============================] - 109s 14ms/step - loss: 0.3786 - gender_loss: 0.1585 - age_loss: 0.2202 - gender_acc: 0.9349 - age_acc: 0.9162 - val_loss: 0.7445 - val_gender_loss: 0.2953 - val_age_loss: 0.4492 - val_gender_acc: 0.8818 - val_age_acc: 0.8103\n",
            "Epoch 13/20\n",
            "7713/7713 [==============================] - 109s 14ms/step - loss: 0.3403 - gender_loss: 0.1521 - age_loss: 0.1882 - gender_acc: 0.9407 - age_acc: 0.9296 - val_loss: 0.8286 - val_gender_loss: 0.3118 - val_age_loss: 0.5168 - val_gender_acc: 0.8777 - val_age_acc: 0.8284\n",
            "Epoch 14/20\n",
            "7713/7713 [==============================] - 109s 14ms/step - loss: 0.3015 - gender_loss: 0.1312 - age_loss: 0.1703 - gender_acc: 0.9479 - age_acc: 0.9371 - val_loss: 1.1234 - val_gender_loss: 0.3481 - val_age_loss: 0.7753 - val_gender_acc: 0.8595 - val_age_acc: 0.7102\n",
            "Epoch 15/20\n",
            "7713/7713 [==============================] - 109s 14ms/step - loss: 0.2626 - gender_loss: 0.1067 - age_loss: 0.1559 - gender_acc: 0.9603 - age_acc: 0.9414 - val_loss: 0.9066 - val_gender_loss: 0.3354 - val_age_loss: 0.5711 - val_gender_acc: 0.8756 - val_age_acc: 0.8351\n",
            "Epoch 16/20\n",
            "7713/7713 [==============================] - 109s 14ms/step - loss: 0.2462 - gender_loss: 0.1150 - age_loss: 0.1311 - gender_acc: 0.9579 - age_acc: 0.9536 - val_loss: 0.8825 - val_gender_loss: 0.3214 - val_age_loss: 0.5610 - val_gender_acc: 0.8751 - val_age_acc: 0.8149\n",
            "Epoch 17/20\n",
            "7713/7713 [==============================] - 109s 14ms/step - loss: 0.2095 - gender_loss: 0.0855 - age_loss: 0.1240 - gender_acc: 0.9699 - age_acc: 0.9568 - val_loss: 1.0182 - val_gender_loss: 0.3966 - val_age_loss: 0.6216 - val_gender_acc: 0.8771 - val_age_acc: 0.8320\n",
            "Epoch 18/20\n",
            "7713/7713 [==============================] - 109s 14ms/step - loss: 0.1993 - gender_loss: 0.0874 - age_loss: 0.1119 - gender_acc: 0.9667 - age_acc: 0.9607 - val_loss: 0.9598 - val_gender_loss: 0.4430 - val_age_loss: 0.5168 - val_gender_acc: 0.8663 - val_age_acc: 0.8248\n",
            "Epoch 19/20\n",
            "7713/7713 [==============================] - 109s 14ms/step - loss: 0.1796 - gender_loss: 0.0850 - age_loss: 0.0946 - gender_acc: 0.9680 - age_acc: 0.9686 - val_loss: 1.0497 - val_gender_loss: 0.4372 - val_age_loss: 0.6125 - val_gender_acc: 0.8647 - val_age_acc: 0.8077\n",
            "Epoch 20/20\n",
            "7713/7713 [==============================] - 109s 14ms/step - loss: 0.1665 - gender_loss: 0.0675 - age_loss: 0.0990 - gender_acc: 0.9750 - age_acc: 0.9673 - val_loss: 0.9397 - val_gender_loss: 0.3993 - val_age_loss: 0.5404 - val_gender_acc: 0.8839 - val_age_acc: 0.8388\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3KhBbLkwUI9W",
        "colab_type": "code",
        "outputId": "fd91ff70-6abc-4b15-bae8-fb991f92ba95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once in a notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Create & upload a file.\n",
        "uploaded = drive.CreateFile({'title': 'age_and_gender2.h5'})\n",
        "uploaded.SetContentFile('age_and_gender2.h5')\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file with ID 1w9M4R06EGKqi37RuwquZiLBxr24fAro5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8WxtiGVA9Fhh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pkill -9 -f ipykernel_launcher"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I2BWNcy89GmT",
        "colab_type": "code",
        "outputId": "14913074-1100-450d-8d70-4a8ca12ef67b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.3.0)\r\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gputil) (1.14.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.7)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.7 GB  | Proc size: 140.1 MB\n",
            "GPU RAM Free: 11438MB | Used: 1MB | Util   0% | Total 11439MB\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
